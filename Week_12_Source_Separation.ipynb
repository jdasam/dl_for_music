{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99137481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nussl\n",
    "import scaper\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# These two libraries are from https://github.com/source-separation/tutorial \n",
    "from common import data\n",
    "from common import viz\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "\n",
    "dataset_path = \"~/userdata/datasets/musdb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f21d7",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"~/userdata/datasets/musdb\"\n",
    "musdb_train = nussl.datasets.MUSDB18(dataset_path, subsets='train', split=\"train\")\n",
    "musdb_valid = nussl.datasets.MUSDB18(dataset_path, subsets='train', split=\"valid\")\n",
    "musdb_test = nussl.datasets.MUSDB18(dataset_path, subsets='test')\n",
    "len(musdb_train), len(musdb_valid), len(musdb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb80cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item = musdb_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item['mix'].audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item['sources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is usually subscriptable,\n",
    "display(Audio(musdb_train[0]['mix'].audio_data, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(train_item['sources']['vocals'].audio_data, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a modified version of tutorial.common.data.prepare_data\n",
    "# It will split the STEM audio file into each source and split\n",
    "for i, musdb in enumerate([musdb_train, musdb_valid, musdb_test]):\n",
    "  _folder = Path(dataset_path) / [\"train\", \"valid\", \"test\"][i]\n",
    "  _folder = _folder.expanduser()\n",
    "  _folder.mkdir(exist_ok=True)\n",
    "  for item in tqdm.tqdm(musdb):\n",
    "    song_name = item['mix'].file_name\n",
    "    for key, val in item['sources'].items():\n",
    "      src_path = _folder / key \n",
    "      src_path.mkdir(exist_ok=True)\n",
    "      src_path = str(src_path / song_name) + '.wav'\n",
    "      val.write_audio_to_file(src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d9239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.on_the_fly makes a new mixture from source\n",
    "\n",
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
    "duration = 10\n",
    "\n",
    "trainset = data.on_the_fly(stft_params, transform=None, fg_path=dataset_path+\"/train\", num_mixtures=500, duration=duration)\n",
    "item = trainset[0]\n",
    "viz.show_sources(item['sources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(item['metadata']['jam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68a364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(item)\n",
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22364e09",
   "metadata": {},
   "source": [
    "### Transform Data\n",
    "- We have to transform nussl.core.AudioSignal into desired format\n",
    "    1. We want to make One Vs All separation system. Therefore, we have to combine the sources except target\n",
    "        - If you want to make vocal separator, you can mix drum, bass, and other as a single source\n",
    "        - If you want to make drum separator, you can mix vocal, bass, and other as a single source\n",
    "    2. We want to use spectrogram instead of waveform audio samples \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af386a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nussl.datasets import transforms as nussl_tfm\n",
    "\n",
    "item = trainset[0]\n",
    "sum_sources = nussl_tfm.SumSources([['vocals', 'drums', 'other']])\n",
    "transformed_item = sum_sources(item)\n",
    "print(transformed_item['sources'])\n",
    "viz.show_sources(transformed_item['sources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e57809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Magnitude Spectrogram np.abs(AudioSignal.stft())\n",
    "msa = nussl_tfm.MagnitudeSpectrumApproximation()\n",
    "\n",
    "item = trainset[0]\n",
    "\n",
    "transformed_item = msa(item)\n",
    "print(transformed_item.keys())\n",
    "print(transformed_item['source_magnitudes'].shape)\n",
    "\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.subplot(4,1,1)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,0]), origin='lower', aspect='auto')\n",
    "plt.subplot(4,1,2)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,1]), origin='lower', aspect='auto')\n",
    "plt.subplot(4,1,3)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,2]), origin='lower', aspect='auto')\n",
    "plt.subplot(4,1,4)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'][...,3]), origin='lower', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f02572",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_sources = nussl_tfm.IndexSources('source_magnitudes', 0)\n",
    "transformed_item = index_sources(msa(item))\n",
    "print(transformed_item['source_magnitudes'].shape)\n",
    "plt.imshow(np.log10(transformed_item['source_magnitudes'].squeeze()), origin='lower', aspect='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698281a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(transformed_item['source_magnitudes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2b8c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_tensor = nussl_tfm.ToSeparationModel()\n",
    "item = trainset[0]\n",
    "transformed_item = to_tensor(index_sources(msa(item)))\n",
    "print(transformed_item.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_item['source_magnitudes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc22c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "item = trainset[0]\n",
    "print(\"Before transforms\")\n",
    "for key in item:\n",
    "    print(key, type(item[key]))\n",
    "print(\"\\nAfter transforms\")\n",
    "item = tfm(item)\n",
    "for key in item:\n",
    "    print(key, type(item[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "duration = 5\n",
    "trainset = trainset = data.on_the_fly(stft_params, \n",
    "                                      transform=tfm, \n",
    "                                      fg_path=dataset_path+\"/train\", \n",
    "                                      num_mixtures=10000000,\n",
    "                                      time_stretch=None,\n",
    "                                      duration=duration)\n",
    "item = trainset[0]\n",
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validset = data.on_the_fly(stft_params, transform=tfm, fg_path=dataset_path+\"/valid\", num_mixtures=64,time_stretch=None, duration=duration)\n",
    "testset = data.on_the_fly(stft_params, transform=tfm, fg_path=dataset_path+\"/test\", num_mixtures=32,time_stretch=None, duration=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params.window_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b2e87",
   "metadata": {},
   "source": [
    "## Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee544be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separator(nn.Module):\n",
    "  def __init__(self, num_freq,hidden_size):\n",
    "    super().__init__()\n",
    "    self.amp_to_db = torchaudio.transforms.AmplitudeToDB(stype='magnitude')\n",
    "    self.batch_norm = nn.BatchNorm2d(num_freq)\n",
    "    self.rnn = nn.LSTM(input_size=num_freq, hidden_size=hidden_size, num_layers=3, bidirectional=True, batch_first=True, dropout=0.3)\n",
    "    self.linear = nn.Linear(hidden_size*2, num_freq)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    db_spec = self.amp_to_db(x.float())\n",
    "    db_spec = db_spec.permute(0,2,1,3)\n",
    "    norm_spec = self.batch_norm(db_spec)\n",
    "    norm_spec = norm_spec.permute(0,2,1,3)[..., 0]\n",
    "    \n",
    "    hidden, _ = self.rnn(norm_spec)\n",
    "    mask = self.linear(hidden).sigmoid().unsqueeze(-1)\n",
    "    masked_output = x.float() * mask\n",
    "    \n",
    "    return {'mask': mask, 'estimation': masked_output}\n",
    "\n",
    "model = Separator(num_freq=stft_params.window_length//2+1, hidden_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_example = nn.LSTM(input_size=1, hidden_size=2, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dummy = torch.arange(12).view(1,-1,1).float()\n",
    "input_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf8b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output, hidden_states = rnn_example(input_dummy)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1985e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_state, c_state = hidden_states\n",
    "h_state, c_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42664d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=16, num_workers=4)\n",
    "valid_loader = DataLoader(validset, batch_size=32)\n",
    "# batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329779e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_spec = batch['mix_magnitude']\n",
    "model(mix_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['mix_magnitude'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5496e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = model\n",
    "x = batch['mix_magnitude']\n",
    "\n",
    "db_spec = self.amp_to_db(x.float())\n",
    "db_spec = db_spec.permute(0,2,1,3)\n",
    "norm_spec = self.batch_norm(db_spec)\n",
    "norm_spec = norm_spec.permute(0,2,1,3)[..., 0]\n",
    "\n",
    "hidden, _ = self.rnn(norm_spec)\n",
    "mask = self.linear(hidden).sigmoid().unsqueeze(-1)\n",
    "masked_output = x.float() * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b69700",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0].transpose(0,1), aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0afb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(db_spec[0], aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bcd2a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(norm_spec[0].detach().permute(1,0), aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630ab37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(hidden[0].detach().permute(1,0), aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc6dcbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask[0].detach().permute(1,0,2), aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d020bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masked_output[0].detach().permute(1,0,2), aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40bf9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(batch['source_magnitudes'][0][...,0].transpose(0,1), aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff= batch['source_magnitudes'][0][...,0].transpose(0,1) - masked_output[0].detach().permute(1,0,2)\n",
    "plt.imshow(diff, aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_l1_loss(pred, target):\n",
    "  return torch.mean(torch.abs(pred-target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7781b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, train_loader, valid_loader, loss_func, num_iter, valid_iter, device):\n",
    "  model = model.to(device)\n",
    "  itr = 0\n",
    "  train_loss_record = []\n",
    "  valid_loss_record = []\n",
    "  model.train()\n",
    "  iter_train_loader = iter(train_loader)\n",
    "  for itr in tqdm.tqdm(range(num_iter)):\n",
    "    batch = next(iter_train_loader)\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(batch['mix_magnitude'].to(device))\n",
    "    loss = loss_func(pred['estimation'], batch['source_magnitudes'][..., 0].to(device))\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimizer.step()\n",
    "    train_loss_record.append(loss.item())\n",
    "    if itr % valid_iter == 0:\n",
    "      model.eval()\n",
    "      valid_loss = 0\n",
    "      with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "          pred = model(batch['mix_magnitude'].to(device))\n",
    "          loss = loss_func(pred['estimation'], batch['source_magnitudes'][..., 0].to(device))\n",
    "          valid_loss = loss.item() * len(batch['mix_magnitude'])\n",
    "      valid_loss_record.append(valid_loss/len(valid_loader.dataset))\n",
    "      model.train()\n",
    "  return {'train': train_loss_record, 'valid':valid_loss_record}\n",
    "\n",
    "    \n",
    "train_loader = DataLoader(trainset, shuffle=True, batch_size=32, num_workers=4)\n",
    "valid_loader = DataLoader(validset, batch_size=32, num_workers=0)\n",
    "\n",
    "model = Separator(num_freq=stft_params.window_length//2+1, hidden_size=256)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "result = train_loop(model, optimizer, train_loader, valid_loader, spec_l1_loss, 100, 50, device='cuda')\n",
    "model = model.to('cpu')\n",
    "torch.save(model.state_dict(), 'vocal_separator_lstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vocal_separator_lstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('vocal_separator_lstm_large.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8594dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63192c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result['train'])\n",
    "# plt.plot(list(range(0, 10000, 200)), result['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824cfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c06691",
   "metadata": {},
   "source": [
    "# 3. Test on custom audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d469d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_path = \"01 범 내려온다_Tiger is Coming.wav\"\n",
    "audio_path = \"/home/teo/userdata/datasets/musdb/test/Zeno - Signs.stem.mp4\"\n",
    "audio_signal = nussl.AudioSignal(audio_path)\n",
    "\n",
    "audio_signal.stft_params = stft_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = audio_signal.to_mono().stft()\n",
    "magnitude_spec = np.abs(spec)\n",
    "input_tensor = torch.Tensor(magnitude_spec).float()\n",
    "input_tensor = torch.stack([input_tensor, input_tensor], dim=0).permute(0,2,1,3)\n",
    "print(input_tensor.shape)\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "with torch.no_grad():\n",
    "  result = model(input_tensor.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1116d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result['mask'][0].cpu().permute(1,0,2), aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_spec = result['estimation'][0].cpu().numpy().transpose(1,0,2)\n",
    "masked_spec = masked_spec* np.exp(1j * np.angle(spec))\n",
    "\n",
    "print(masked_spec.shape)\n",
    "recon_signal = nussl.AudioSignal(stft=masked_spec, sample_rate=audio_signal.sample_rate, stft_params=stft_params)\n",
    "recon_audio = recon_signal.istft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16362077",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(recon_audio, rate=recon_signal.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34f2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_spec = batch['mix_magnitude']\n",
    "mix_spec = torchaudio.transforms.AmplitudeToDB()(mix_spec)\n",
    "print(mix_spec.shape) # N T F C\n",
    "mix_spec = mix_spec.permute(0,2,1,3) # N F T C\n",
    "nn.BatchNorm2d(257)(mix_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5490eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['source_magnitudes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb973460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f269f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc0c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f5e0618a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
